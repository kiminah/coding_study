 # 감정 분석

- 텍스트의 긍정/부정을 판단하는 분석 방법

##### 비지도 학습 (non target learning) : 사전 기반의 감정 분석

- 감정지수 사전 (맛있(3점), 참(2점), 너무(-1점), 맛없(-3점))

- 이 집은 참 맛있어요 : 2점 긍정
- 이 집은 너무 맛있어요 : 0점 중립
- 사전 긍정/부정 사전
- 맛있, 참 / 맛없, 너무 → 1점, 1점  → 0점 중립

##### 지도학습 (target learning) : label을 이용한 머신러닝

- 이 집은 참 맛있어요
- 여기는 맛 없네

|                     | 이   | 집은 | 참   | 맛있어요 | 여기는 | 맛   | 없네 |
| ------------------- | ---- | ---- | ---- | -------- | ------ | ---- | ---- |
| 이 집은 참 맛있어요 | 1    | 1    | 1    | 1        | 0      | 0    | 0    |
| 여기는 맛 없네      | 0    | 0    | 0    | 0        | 1      | 1    | 1    |

- 위 형태를 머신러닝 알고리즘에 넣어서 학습 시킴

  

- 성능은 지도학습이 훨씬 높다(단, label data 크기에 따라 달라진다.)

- 신뢰성을 증명하려면 샘플데이터에 직접 라벨링을 해서 사전을 구성하고 예측하는 작업을 함



## 사전을 이용한 분석

#### 01. 긍/부정 사전

- 형태소를 보고 계속 추가

  ```R
  library(KoNLP)
  # 형태소 분리해 보고 싶은 문자열 test 하여 사전에 추가
  SimplePos09(c('맛있다','맛있네요','맛있엇어요','맛있습니다')) 
  SimplePos09(c('친절하네요','친절함','친절하다','친절합니다')) 
  
  posi <- c('합리적인','호강','맛있','정말강추','좋았','최고','맛있습니','친절하네','친절',
            '친절하','친절합니','진짜맛','정말강','매꼼한','쵝오','좋','친절','깔끔','저렴',
            '편하','훈남','훈녀','괜찮','맛나','나쁘진','잘하는집','대박나','백터지게','최고',
            '최고인것같아요','너무맛있네요','마시써영','마시써','자주시켜먹을꼐','번창하셨으면좋겠어요',
            '좋','아주친절','맛있','잘먹었네')
  nega <- c('맛 없','낚였네요','밥맛뚝뚝','맛은별로','접으세요','싫','시켜먹','없으신가봐요',
            '안받네요','못먹어요','절대','토할것만같아요','비위생','맛이왜이러지','맛없','더럽',
            '미숙함','썰렁','맛도없다','불친절','망','꺼지라','꽝','취소','불퀘하면')
  ```

#### 02. sample 추출해서 확인

```R
sample_index <- sample(1:length(comments),1000)

## 데이터 추출
sample_com <- comments[sample_index]
sample_score <- score[sample_index]
```

#### 03. 형태소 분석

```R
com_list <- list() # 결과 담을 빈 리스트 생성

for(i in 1:length(sample_com)){
  if(class(try(s_token <- SimplePos09(sample_com[i])))=='try-error'){
    com_list[[i]] <- NA
  }else{
    com_list[[i]] <- s_token
  }
  cat('\n', i) # 진행 상황 확인용
}

com_list[[1]]
# $새로운게
# [1] "새롭/P+은게/E"
# 
# $먹고
# [1] "먹/P+고/E"
# 
# $싶어서
# [1] "싶/P+어서/E"
# 
# $가족과
# [1] "가족/N+과/J"
# 
# $모처럼
# [1] "모처럼/M"
```

#### 04. 형태소 분석된 요소 맨 앞 글자만 가져오기

- 함수로 구현

  ```R
  sel <- function(x){
    sapply(str_split(x,'/'),function(x){x[1]})
  }
  
  com_list2 <- sapply(com_list, sel)
  ```

#### 05. 긍/부정 사전을 이용하여 점수 합산

```R
## 모든 리뷰에 대하여 형태소 확인
posi_list <- list() # 긍정사전 매칭 결과
nega_list <- list() # 부정사전 매칭 결과
score_list <- c() # 매칭결과 합산

for(j in 1:length(com_list2)){
  posi_list[[j]] <- posi[(posi %in% com_list2[[j]])]
  nega_list[[j]] <- nega[(nega %in% com_list2[[j]])]
  posi_score <- sum(posi %in% com_list2[[j]]) # 긍정점수
  nega_score <- -sum(nega %in% com_list2[[j]]) # 부정점수
  text_score <- posi_score + nega_score # 긍/부정 합산산
  score_list[j] <- text_score
  cat('\n',j)
}

final_score <- ifelse(score_list > 0 ,'긍정','부정')
table(final_score) # sample data로 추측한 긍부정 분포
# 긍정 부정 
# 450  550 

hist(score_list) # 히스토그램으로 긍부정 확인
```



<img src="C:%5CUsers%5Ckimih%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210329231715889.png" alt="image-20210329231715889" style="zoom:50%;" />

#### 06. 예측 결과 확인

```R
## sample_score 파일에 평점이 있고 추출한 sample_com과 같은 index에서 추출
## 3점보다 높으면 긍정, 아니면 부정
true_score <- ifelse(sample_score >3, '긍정','부정')
table(true_score) # 실제 긍부정 분포
# 긍정 부정 
# 574  426 

# 예측율 계산
sum(final_score==true_score)/1000 # 0.712 : 약 70%의 예측률 확인
```

#### 07. 예측이 틀린 데이터 확인 및 역추적

```R
which(final_score != true_score)

index <- 669 # 위 코드에서 나온 index 중 하나 선택
sample_score[index] # 수집
sample_com[index] # 수집
final_score[index] # 예측

SimplePos09('정말 맛있게 잘먹었네요 ')

# 0.7 # 직접만든 사전으로 분석한 결과
# 0.708 # 직접만든 사전에 추가적인 요소 추가하여 분석한 결과
```

