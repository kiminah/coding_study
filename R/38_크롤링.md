# 크롤링

```R
# revest 패키지 사용
install.packages("rvest")
library(rvest)
```



## 기본 크롤링 방법

### 1. 요청 

- read_html(uri) : uri를 서버에 요청해서 응답받아주는 함수

  ```R
  url <- "원하는 페이지 url"
  
  nv <- read_html(url) # # 요청 후 응답받은 html 코드를 저장
  class(nv) # "xml_document" "xml_node"
  mode(nv) # "list"
  ```

  

### 2. 읽어온 페이지에서 필요한 node(tag)만 추출
- html_nodes(html 객체, '찾을패턴 : selector나 xpath')

  ```R
  nv_node <- html_nodes(nv, '#content > div > div > h2')
  ```

  

### 3. 필요한 데이터만 추출

- html_text(node 객체) : 태그 내 text 추출

- html_attr(node 객체, 속성명) : node 객체의 해당 속성 값 추출

  ```R
  nv_text <- html_text(nv_node)
  ```

  

### 4. 데이터 정체(불용어 제거)

- stringr::str_replace_al()

- gsub()

  ```R
  # 특수기호 제거
  # 모든 특수기호 정규식 : '[[:punct:]]'
  text <- str_replace_all(nv_text, '[[:punct:]]','')
  text <- gsub("\\n|\\t",'', text)
  text <- gsub('\u97d3', '', text)
  ```



## 지도 크롤링

- 개발자 도구 네트워크 기능 이용해서 쿼리 리서치 api 데이터 이용

  #### 1. base url 지정 후, 검색하고자 하는 키워드 병합

  - iconv(str, from, to) : 인코딩 빙식을 변경해주는 함수

  ```R
  keyword <- '신촌카페'
  # 윈도우 엔코딩 방식인 cp949 -> 웹 엔코딩 방식 utf-8로 변경
  keyword <- iconv(keyword, from="CP949", to="UTF-8")
  ```

  - URLencode() : 퍼센트 인코딩으로 변경

  ```R
  keyword2 <- URLencode(keyword)
  ## url이나 api 요청을 위한 헤더 정보를 생성할 때 공백이 추가되면 안된다.
  base_url <- paste0(base_url, keyword2, query)
  ```

  #### 2. 데이터 가져오기

  - 데이터가 json 형태 일때 readLines로 읽어서 구조 변환

  ```R
  raw_text <- readLines(url, encoding='UTF-8')
  ```

  - json 변경 전에 모든 데이터를 결합

  ```R
  raw_text <- paste(raw_text, collapse=" ")
  ```

  - json 형태로 변환

  ```R
  library(RJSONIO)
  
  raw_json <- fromJSON(raw_text)
  
  # 이 후는 원하는 요소 크롤링
  ```



## etc

- 크롤링한 이미지 저장방법

  ```R
  for(i in 1:length(img_url)){
    file_name <- paste0(keyword,i,'.jpg') # 파일명 지정
    download.file(img_url[i],file_name, mode='wb') # img_url : 이미지 경로
  }
  ```

  



