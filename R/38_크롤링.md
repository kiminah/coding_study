# 크롤링

```R
# revest 패키지 사용
install.packages("rvest")
library(rvest)
```



## 기본 크롤링 방법

### 1. 요청 

- read_html(uri) : uri를 서버에 요청해서 응답받아주는 함수

  ```R
  url <- "원하는 페이지 url"
  
  nv <- read_html(url) # # 요청 후 응답받은 html 코드를 저장
  class(nv) # "xml_document" "xml_node"
  mode(nv) # "list"
  ```

  

### 2. 읽어온 페이지에서 필요한 node(tag)만 추출
- html_nodes(html 객체, '찾을패턴 : selector나 xpath')

  ```R
  nv_node <- html_nodes(nv, '#content > div > div > h2')
  ```

  

### 3. 필요한 데이터만 추출

- html_text(node 객체) : 태그 내 text 추출

- html_attr(node 객체, 속성명) : node 객체의 해당 속성 값 추출

  ```R
  nv_text <- html_text(nv_node)
  ```

  

### 4. 데이터 정체(불용어 제거)

- stringr::str_replace_al()

- gsub()

  ```R
  # 특수기호 제거
  # 모든 특수기호 정규식 : '[[:punct:]]'
  text <- str_replace_all(nv_text, '[[:punct:]]','')
  text <- gsub("\\n|\\t",'', text)
  text <- gsub('\u97d3', '', text)
  ```





