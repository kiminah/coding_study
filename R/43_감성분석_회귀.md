# 감성분석_회귀

### 선형 회귀분석모델을 이용한 감성분석

- 회귀 축소법(Lasso/Ridge) 사용
- y = wx + b
  - x : 문서 내 특정 단어의 빈도
  - y : 문서의 긍/부정
  - w :  가중치 / 계수
  - b : 절편 또는 편향
  - 가중치가 `+`면 : 긍정단어
  - 가중치가 `-`면 : 부정단어

- DTM 형식으로 데이터 전달

  1) 형태소 분석기 없이 공백으로 구분하여 데이터 사용

  2) 형태소 분석기를 사용해서 구분한 후에 데이터 전달



#### 01. sample 추출

```R
sample_index <- sample(1:length(comments),1000)

## sample 데이터 추출
sample_com <- comments[sample_index]
sample_score <- score[sample_index]
```

#### 02. 형태소 공백으로 구분

```R
## 공백으로 분리 후 작업
sample_com_space <- str_split(sample_com," ")
word_list <- unlist(sample_com_space)
```

#### 03. 빈도표 생성

```R
terms <- table(word_list)

# 공백을 기준으로 분리한 단어 중 발생 빈도가 높은 300개 추출해서 terms로 사용
terms_fin <- sort(terms, decreasing=T)[1:300] # terms가 커질수록 성능은 좋아지지만 메모리 생김

terms_fin <- names(terms_fin)[-1] # 가장 높은 빈도는 공백이라서 제외
```

#### 04. DTM 작성

```R
dtm <- matrix(0, ncol=length(terms_fin),nrow=length(sample_com))
colnames(dtm) <- terms_fin
head(dtm) # 매칭되면 1, 아니면 0 값으로 변경하는 작업을 수행하게 되는 행렬
```

#### 05. sample data에 대해서 DTM 설정

```R
# 1번 리뷰
sample_com[1] 
# 1번 리뷰에 대해 공백 기준으로 분리
sample_com_space[[1]]

# terms_fin이 공백으로 분리된 문자안에 있으면 1로 변경
dtm[1, terms_fin %in% sample_com_space[[1]]] <- 1

## 모든 sample data에 대해서 DTM 설정
for(i in 1:length(sample_com)){
    dtm[i, terms_fin %in% sample_com_space[[i]]] <- 1
    cat("\n", i) # 진행상황 파악
}
```

#### 06. 리뷰처럼 score도 설정

```R
# 평점 3점 초과는 1, 3점 이하는 0
sample_score2 <- ifelse(sample_score>3, 1, 0)

## dtm의 각 행을 더해서 0이 아닌 행의 index 추출 : terms가 있는 행만 추출
## apply(df, 1|0, func) : 행방향(1), 열방향(0)
data_index <- apply(dtm,1,sum) != 0

dtm_t <- dtm[data_index,] # 해당 data 위치를 1로 변경
sample_fin <- sample_com_space[data_index] 
score_t <- sample_score2[data_index]

dim(dtm_t) # 879 299 : matrix이기 때문에 length로 확인하면 (행x열)의 값이 나온다.
length(sample_fin) # 879
length(score_t) # 879
```

#### 07. 회귀 축소법

- glmnet 패키지 사용
- `alpha =1` : lasso / `alpha=0` : ridge
- 하이퍼파라미터로 lambda를 사용하고 있음
- 값이 0과 1을 갖는 이항인 경우에는 `family="binomial"`로 설정해야 함

```R
install.packages("glmnet")
library(glmnet)

fit <- glmnet(dtm_t, score_t, alpha=1, family = 'binomial')

s <- fit$lambda[length(fit$lambda)]
coef(fit, s=s) ## 긍/부정 지수 산출
# 너무           -2.07382213 # 부정
# 진짜            0.33032062 # 긍정
# 여기            0.20676623
# 그냥          -18.12427473
# 완전           -2.47806629
# 맛있어요        3.81256832 # 긍정
```

#### 08. 예측 테스트

- lasso 로 확인

```R
### sample 데이터를 train/test로 분류
train <- sample(1:length(score_t),length(score_t)*0.7)

## 70%는 학습데이터 이용
fit <- glmnet(dtm_t[train,], score_t[train], alpha=1, family = 'binomial')
s <- fit$lambda[length(fit$lambda)]

## 예측 테스트
pred <- predict(fit, dtm_t[-train,], s=s)
pred_fin <- ifelse(pred>0, 1,0)
sum(pred_fin==score_t[-train])/length(pred_fin)
# 예측률 : 0.6856061
```

- ridge로 확인

```R
## 70%는 학습데이터 이용
fit <- glmnet(dtm_t[train,], score_t[train], alpha=0, family = 'binomial')
s <- fit$lambda[length(fit$lambda)]

## 예측 테스트
pred <- predict(fit, dtm_t[-train,], s=s)
pred_fin <- ifelse(pred>0, 1,0)
sum(pred_fin==score_t[-train])/length(pred_fin)
# 예측률 : 0.7386364
```

> ridge가 평균적으로 조금 더 높게 나옴 - 더 많은 변수를 사용하기 때문인듯?